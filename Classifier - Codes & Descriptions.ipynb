{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* author: Yunlu Huang\n",
    "* email: yunluh@andrew.cmu.edu\n",
    "\n",
    "<FONT COLOR = 'RED'>以下内容包含处理数据的代码 & 思路详细解释（具体看每个部分的 `处理思路`）</FONT>\n",
    "\n",
    "# 目录\n",
    "\n",
    "* [STEP 0. 读取训练数据 (Development Data)](#read)\n",
    "* [STEP 1. 样本处理：缺失值、异常值、重复值](#step1-1)\n",
    "> * [STEP 1-1. 处理缺失值](#step1-1)\n",
    "> * [STEP 1-2. 处理异常值、重复值](#step1-2)\n",
    "* [STEP 2. 变量处理：日期处理、数值标准化、分类变量处理](#step2-1)\n",
    "> * [STEP 2-1. 日期处理](#step2-1)\n",
    "> * [STEP 2-2. 数值标准化](#step2-2)\n",
    "> * [STEP 2-3. 分类变量处理](#step2-3)\n",
    "* [其他：检验数据 (Assessment Data) 清洗](#assessment)\n",
    "* [STEP 3. 数据不均衡：综合采样](#resample)\n",
    "* [STEP 4. 特征选择 & 特征提取](#features)\n",
    "* [STEP 5. 建模](#models)\n",
    "> * [STEP 5-1. Logistic Regression](#lr)\n",
    "> * [STEP 5-2. SVM](#svm)\n",
    "> * [STEP 5-3. Random Forest](#rf)\n",
    "* [STEP 6. 模型选择](#selection)\n",
    "* [STEP 7. 分类预测](#prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import math\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pyxlsb import convert_date\n",
    "from pyxlsb import open_workbook\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.utils import resample \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"read\"></a>\n",
    "# STEP 0. 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "wb = open_workbook('development_sample.xlsb')\n",
    "sheet = wb.get_sheet('DEV')\n",
    "data = []\n",
    "for i, row in enumerate(sheet.rows()):\n",
    "    row_cells = []\n",
    "    for j, cell in enumerate(row):\n",
    "        row_cells.append(convert_date(cell.v) if j == 4 and i > 0 else cell.v)\n",
    "    data.append(row_cells)\n",
    "wb.close()\n",
    "# generate the dataframe based on the data\n",
    "df = pd.DataFrame(data, columns=data[0])\n",
    "df = df.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the dataframe\n",
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>ID2</th>\n",
       "      <th>LOYALTY_STATUS</th>\n",
       "      <th>WEEK_DAY</th>\n",
       "      <th>DDATE</th>\n",
       "      <th>SOCIAL_STATUS</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>AGE_RANGE</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>COMPFIELD</th>\n",
       "      <th>...</th>\n",
       "      <th>DIF_CELLTEL_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_CELLTEL_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_CELLTEL_LAST_30_</th>\n",
       "      <th>DIF_CNT_SPEC_ALLPERIOD</th>\n",
       "      <th>DIF_INN_CNT_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_3PERTEL_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_HOMETEL_ALLPERIOD</th>\n",
       "      <th>FIRST_DEALNO_LAG</th>\n",
       "      <th>DIF_INN_BY_COMPTEL_LAST_180_</th>\n",
       "      <th>DIF_INN_BY_COMPTEL_LAST_30_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-12-01 00:00:00</td>\n",
       "      <td>wage worker</td>\n",
       "      <td>11</td>\n",
       "      <td>40-44</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2004-12-01 00:00:00</td>\n",
       "      <td>self-emplyed</td>\n",
       "      <td>13-17</td>\n",
       "      <td>&gt;54</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-12-01 00:00:00</td>\n",
       "      <td>wage worker</td>\n",
       "      <td>13-17</td>\n",
       "      <td>35-39</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2004-12-01 00:00:00</td>\n",
       "      <td>self-emplyed</td>\n",
       "      <td>11</td>\n",
       "      <td>26-29</td>\n",
       "      <td>secondary</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-12-01 00:00:00</td>\n",
       "      <td>self-emplyed</td>\n",
       "      <td>&gt;18</td>\n",
       "      <td>40-44</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>04</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  TARGET ID2 LOYALTY_STATUS WEEK_DAY                DDATE SOCIAL_STATUS  \\\n",
       "1      0   1              0        1  2004-12-01 00:00:00   wage worker   \n",
       "2      1   2              0        6  2004-12-01 00:00:00  self-emplyed   \n",
       "3      0   3              0        1  2004-12-01 00:00:00   wage worker   \n",
       "4      0   4              0        5  2004-12-01 00:00:00  self-emplyed   \n",
       "5      0   5              0        4  2004-12-01 00:00:00  self-emplyed   \n",
       "\n",
       "    HOUR AGE_RANGE        EDUCATION COMPFIELD             ...              \\\n",
       "1     11     40-44  upper-secondary        02             ...               \n",
       "2  13-17       >54  upper-secondary        01             ...               \n",
       "3  13-17     35-39  upper-secondary        02             ...               \n",
       "4     11     26-29        secondary        12             ...               \n",
       "5    >18     40-44  upper-secondary        04             ...               \n",
       "\n",
       "  DIF_CELLTEL_ALLPERIOD DIF_INN_BY_CELLTEL_ALLPERIOD  \\\n",
       "1                     0                            0   \n",
       "2                     0                            0   \n",
       "3                     0                            0   \n",
       "4                     0                            0   \n",
       "5                     0                            0   \n",
       "\n",
       "  DIF_INN_BY_CELLTEL_LAST_30_ DIF_CNT_SPEC_ALLPERIOD DIF_INN_CNT_ALLPERIOD  \\\n",
       "1                           0                      0                     0   \n",
       "2                           0                      0                     0   \n",
       "3                           0                      0                     0   \n",
       "4                           0                      0                     0   \n",
       "5                           0                      3                     0   \n",
       "\n",
       "  DIF_INN_BY_3PERTEL_ALLPERIOD DIF_INN_BY_HOMETEL_ALLPERIOD FIRST_DEALNO_LAG  \\\n",
       "1                            0                            1             None   \n",
       "2                            1                            0             None   \n",
       "3                            0                            0             None   \n",
       "4                            0                            2             None   \n",
       "5                            0                            1             None   \n",
       "\n",
       "  DIF_INN_BY_COMPTEL_LAST_180_ DIF_INN_BY_COMPTEL_LAST_30_  \n",
       "1                            0                           0  \n",
       "2                            0                           0  \n",
       "3                            0                           0  \n",
       "4                            0                           0  \n",
       "5                            0                           0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"step1-1\"></a>\n",
    "# STEP 1-1. 处理缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col#1 \"TARGET\" : 1\n",
      "col#10 \"COMPFIELD\" : 445\n",
      "col#12 \"COMPSTAFFQNTY\" : 1\n",
      "col#13 \"APPWPERIOD_R2\" : 1062\n",
      "col#14 \"APPCHILDQNTY\" : 12127\n",
      "col#64 \"FIRST_DEALNO_LAG\" : 245506\n"
     ]
    }
   ],
   "source": [
    "# count the missing values number in each coloumn\n",
    "for i, col_name in enumerate(data[0]):\n",
    "    count = df_clean[col_name].isnull().sum().sum()\n",
    "    if count > 0:\n",
    "        print(\"col#{} \\\"{}\\\" : {}\".format(i+1, col_name, count))\n",
    "        \n",
    "# The output is:\n",
    "# col#1 \"TARGET\" : 1\n",
    "# col#10 \"COMPFIELD\" : 445\n",
    "# col#12 \"COMPSTAFFQNTY\" : 1\n",
    "# col#13 \"APPWPERIOD_R2\" : 1062\n",
    "# col#14 \"APPCHILDQNTY\" : 12127\n",
    "# col#64 \"FIRST_DEALNO_LAG\" : 245506"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理思路：\n",
    "\n",
    "因为以前没有太多处理缺失值的经验，经过查阅，认为可行的缺失值处理方式如下（摘自知乎”机器学习如何处理缺失值？“ [https://www.zhihu.com/question/26639110] ）：\n",
    "> 1. 平均值、中值、分位数、众数、随机值。缺陷在于：人为增加了噪声\n",
    "> 2. 其他变量做预测模型来算出缺失变量。缺陷在于：如果其他变量和缺失变量无关，则预测的结果无意义；如果预测结果相当准确，则又说明这个变量是没必要加入建模\n",
    "> 3. 最精确的做法，把变量映射到高维空间。比如性别，有男、女、缺失三种情况，则映射成3个变量：是否男、是否女、是否缺失。好处：完整保留了原始数据的全部信息\n",
    "\n",
    "综合以上所得数据，发现缺失值全部为分类变量（没有数值型变量），决定处理以下方式：\n",
    "> 1. 缺失值数量为1的 -> 删除\n",
    "> 2. 其他缺失值 -> 变量映射到高维空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the rows with missing values count = 1\n",
    "df_clean = df_clean.dropna(subset = ['TARGET', 'COMPSTAFFQNTY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the missing value into 'isMissing'\n",
    "df_clean['COMPFIELD'] = df_clean['COMPFIELD'].apply(lambda x: 'isMissing' if x is np.NaN or x is None else x)\n",
    "df_clean['APPWPERIOD_R2'] = df_clean['APPWPERIOD_R2'].apply(lambda x: 'isMissing' if x is np.NaN or x is None else x)\n",
    "df_clean['APPCHILDQNTY'] = df_clean['APPCHILDQNTY'].apply(lambda x: 'isMissing' if x is np.NaN or x is None else x)\n",
    "df_clean['FIRST_DEALNO_LAG'] = df_clean['FIRST_DEALNO_LAG'].apply(lambda x: 'isMissing' if x is np.NaN or x is None else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"step1-2\"></a>\n",
    "# STEP 1-2. 处理异常值、重复值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1-3', 149698),\n",
       " ('0', 134901),\n",
       " ('isMissing', 12127),\n",
       " ('>3', 1143),\n",
       " ('8', 9),\n",
       " ('10', 8),\n",
       " ('9', 6),\n",
       " ('11', 2),\n",
       " ('13', 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the outliers\n",
    "Counter(list(df_clean['APPCHILDQNTY'])).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# check whether there exsits duplicated rows\n",
    "count = 0\n",
    "for i, result in enumerate(df_clean.duplicated()):\n",
    "    if result == True:\n",
    "        count += 1\n",
    "print(count)\n",
    "# there's no duplicated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理思路：\n",
    "\n",
    "异常值：通过对不同列的数据分布进行统计分析，发现 `APPCHILDQNTY` 这一列比较奇怪——已经有`>3`的类别了，还是出现了`8`，`9`，`10`，`11` 和 `13` 的值，而且总数为26个。此外，`HOUR` 仅有一条数据值为 1，`APPWPERIOD_R2` 一条数据值为 0.5，`DIF_INN_BY_CELLTEL_ALLPERIOD`一条数据值为 7.0。\n",
    "> * 把这些异常值归类到 `>3` 中\n",
    "> * 删除其他异常值的数据\n",
    "\n",
    "重复值：数据里没有重复值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1-3', 149698), ('0', 134901), ('isMissing', 12127), ('>3', 1169)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['APPCHILDQNTY'] = df_clean['APPCHILDQNTY'].apply(lambda x: '>3' if x in ['8','9','10','11','13'] else x)\n",
    "# check the outliers\n",
    "Counter(list(df_clean['APPCHILDQNTY'])).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"step2-1\"></a>\n",
    "# STEP 2-1. 日期处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理思路：\n",
    "\n",
    "训练数据中，日期范围在2014年8月~12月，具体日子均为每月1日。仅有月份提供了实际信息。\n",
    "> * 仅把月份提取出来，删除年份、日子信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>ID2</th>\n",
       "      <th>LOYALTY_STATUS</th>\n",
       "      <th>WEEK_DAY</th>\n",
       "      <th>DDATE</th>\n",
       "      <th>SOCIAL_STATUS</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>AGE_RANGE</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>COMPFIELD</th>\n",
       "      <th>...</th>\n",
       "      <th>DIF_CELLTEL_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_CELLTEL_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_CELLTEL_LAST_30_</th>\n",
       "      <th>DIF_CNT_SPEC_ALLPERIOD</th>\n",
       "      <th>DIF_INN_CNT_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_3PERTEL_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_HOMETEL_ALLPERIOD</th>\n",
       "      <th>FIRST_DEALNO_LAG</th>\n",
       "      <th>DIF_INN_BY_COMPTEL_LAST_180_</th>\n",
       "      <th>DIF_INN_BY_COMPTEL_LAST_30_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>wage worker</td>\n",
       "      <td>11</td>\n",
       "      <td>40-44</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>self-emplyed</td>\n",
       "      <td>13-17</td>\n",
       "      <td>&gt;54</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>wage worker</td>\n",
       "      <td>13-17</td>\n",
       "      <td>35-39</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>02</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>self-emplyed</td>\n",
       "      <td>11</td>\n",
       "      <td>26-29</td>\n",
       "      <td>secondary</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>self-emplyed</td>\n",
       "      <td>&gt;18</td>\n",
       "      <td>40-44</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>04</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  TARGET ID2 LOYALTY_STATUS WEEK_DAY  DDATE SOCIAL_STATUS   HOUR AGE_RANGE  \\\n",
       "1      0   1              0        1     12   wage worker     11     40-44   \n",
       "2      1   2              0        6     12  self-emplyed  13-17       >54   \n",
       "3      0   3              0        1     12   wage worker  13-17     35-39   \n",
       "4      0   4              0        5     12  self-emplyed     11     26-29   \n",
       "5      0   5              0        4     12  self-emplyed    >18     40-44   \n",
       "\n",
       "         EDUCATION COMPFIELD             ...              \\\n",
       "1  upper-secondary        02             ...               \n",
       "2  upper-secondary        01             ...               \n",
       "3  upper-secondary        02             ...               \n",
       "4        secondary        12             ...               \n",
       "5  upper-secondary        04             ...               \n",
       "\n",
       "  DIF_CELLTEL_ALLPERIOD DIF_INN_BY_CELLTEL_ALLPERIOD  \\\n",
       "1                     0                            0   \n",
       "2                     0                            0   \n",
       "3                     0                            0   \n",
       "4                     0                            0   \n",
       "5                     0                            0   \n",
       "\n",
       "  DIF_INN_BY_CELLTEL_LAST_30_ DIF_CNT_SPEC_ALLPERIOD DIF_INN_CNT_ALLPERIOD  \\\n",
       "1                           0                      0                     0   \n",
       "2                           0                      0                     0   \n",
       "3                           0                      0                     0   \n",
       "4                           0                      0                     0   \n",
       "5                           0                      3                     0   \n",
       "\n",
       "  DIF_INN_BY_3PERTEL_ALLPERIOD DIF_INN_BY_HOMETEL_ALLPERIOD FIRST_DEALNO_LAG  \\\n",
       "1                            0                            1        isMissing   \n",
       "2                            1                            0        isMissing   \n",
       "3                            0                            0        isMissing   \n",
       "4                            0                            2        isMissing   \n",
       "5                            0                            1        isMissing   \n",
       "\n",
       "  DIF_INN_BY_COMPTEL_LAST_180_ DIF_INN_BY_COMPTEL_LAST_30_  \n",
       "1                            0                           0  \n",
       "2                            0                           0  \n",
       "3                            0                           0  \n",
       "4                            0                           0  \n",
       "5                            0                           0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['DDATE'] = df_clean['DDATE'].apply(lambda x: x.month)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({8: 48249, 9: 49071, 10: 50126, 11: 56163, 12: 94286})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(list(df_clean['DDATE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"step2-2\"></a>\n",
    "# STEP 2-2. 数值标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理思路：\n",
    "\n",
    "在所有变量中，仅 `WEEK_DAY`和`DDATE`为数值，其余均为分类变量。而这两个数值型变量周期并不为10（`WEEK_DAY` 周期为7， `DDATE`周期为12）。\n",
    "> * Time is a cyclic variable. To encode this as a numerical feature, we can use a sine/cosine transformation. Suppose we have a feature of value f that ranges from 0 to N. Then, the sine and cosine transformation would be $\\sin\\left(2\\pi \\frac{f}{N}\\right)$ and $\\cos\\left(2\\pi \\frac{f}{N}\\right)$. For example, the sine transformation of 6 hours would be $\\sin\\left(2\\pi \\frac{6}{24}\\right)$, since there are 24 hours in a cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>ID2</th>\n",
       "      <th>LOYALTY_STATUS</th>\n",
       "      <th>SOCIAL_STATUS</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>AGE_RANGE</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>COMPFIELD</th>\n",
       "      <th>APPFAMILYSTATUS</th>\n",
       "      <th>COMPSTAFFQNTY</th>\n",
       "      <th>...</th>\n",
       "      <th>DIF_INN_CNT_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_3PERTEL_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_HOMETEL_ALLPERIOD</th>\n",
       "      <th>FIRST_DEALNO_LAG</th>\n",
       "      <th>DIF_INN_BY_COMPTEL_LAST_180_</th>\n",
       "      <th>DIF_INN_BY_COMPTEL_LAST_30_</th>\n",
       "      <th>cos_month</th>\n",
       "      <th>cos_week_day</th>\n",
       "      <th>sin_month</th>\n",
       "      <th>sin_week_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>wage worker</td>\n",
       "      <td>11</td>\n",
       "      <td>40-44</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>&gt;50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>0.781831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>self-emplyed</td>\n",
       "      <td>13-17</td>\n",
       "      <td>&gt;54</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>-0.781831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>wage worker</td>\n",
       "      <td>13-17</td>\n",
       "      <td>35-39</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>02</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>0.781831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>self-emplyed</td>\n",
       "      <td>11</td>\n",
       "      <td>26-29</td>\n",
       "      <td>secondary</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>-0.974928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>self-emplyed</td>\n",
       "      <td>&gt;18</td>\n",
       "      <td>40-44</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>-0.433884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  TARGET ID2 LOYALTY_STATUS SOCIAL_STATUS   HOUR AGE_RANGE        EDUCATION  \\\n",
       "1      0   1              0   wage worker     11     40-44  upper-secondary   \n",
       "2      1   2              0  self-emplyed  13-17       >54  upper-secondary   \n",
       "3      0   3              0   wage worker  13-17     35-39  upper-secondary   \n",
       "4      0   4              0  self-emplyed     11     26-29        secondary   \n",
       "5      0   5              0  self-emplyed    >18     40-44  upper-secondary   \n",
       "\n",
       "  COMPFIELD APPFAMILYSTATUS COMPSTAFFQNTY     ...      DIF_INN_CNT_ALLPERIOD  \\\n",
       "1        02               1           >50     ...                          0   \n",
       "2        01               2             1     ...                          0   \n",
       "3        02               4             1     ...                          0   \n",
       "4        12               1             1     ...                          0   \n",
       "5        04               1             1     ...                          0   \n",
       "\n",
       "  DIF_INN_BY_3PERTEL_ALLPERIOD DIF_INN_BY_HOMETEL_ALLPERIOD FIRST_DEALNO_LAG  \\\n",
       "1                            0                            1        isMissing   \n",
       "2                            1                            0        isMissing   \n",
       "3                            0                            0        isMissing   \n",
       "4                            0                            2        isMissing   \n",
       "5                            0                            1        isMissing   \n",
       "\n",
       "  DIF_INN_BY_COMPTEL_LAST_180_ DIF_INN_BY_COMPTEL_LAST_30_ cos_month  \\\n",
       "1                            0                           0       1.0   \n",
       "2                            0                           0       1.0   \n",
       "3                            0                           0       1.0   \n",
       "4                            0                           0       1.0   \n",
       "5                            0                           0       1.0   \n",
       "\n",
       "  cos_week_day     sin_month sin_week_day  \n",
       "1     0.623490 -2.449294e-16     0.781831  \n",
       "2     0.623490 -2.449294e-16    -0.781831  \n",
       "3     0.623490 -2.449294e-16     0.781831  \n",
       "4    -0.222521 -2.449294e-16    -0.974928  \n",
       "5    -0.900969 -2.449294e-16    -0.433884  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['WEEK_DAY'] = df_clean['WEEK_DAY'].astype(int)\n",
    "\n",
    "sin_wd = df_clean['WEEK_DAY'].apply(lambda x: math.sin(2*np.pi*x/float(7)))\n",
    "cos_wd = df_clean['WEEK_DAY'].apply(lambda x: math.cos(2*np.pi*x/float(7)))\n",
    "sin_m = df_clean['DDATE'].apply(lambda x: math.sin(2*np.pi*x/float(12)))\n",
    "cos_m = df_clean['DDATE'].apply(lambda x: math.cos(2*np.pi*x/float(12)))\n",
    "\n",
    "df_clean = df_clean.assign(sin_week_day = sin_wd, \n",
    "                           cos_week_day = cos_wd, \n",
    "                           sin_month = sin_m, \n",
    "                           cos_month = cos_m).drop(['WEEK_DAY', 'DDATE'], axis=1)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"step2-3\"></a>\n",
    "# STEP 2-3. 分类变量处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET  [0.0 1.0]\n",
      "LOYALTY_STATUS  [0.0 1.0]\n",
      "CONTACT_IN_BL  ['0' '1']\n",
      "DIF_CELLTEL_LAST_180DAY  ['0' '>0']\n",
      "DIF_CHILDQNTY_LAST_180DAY  ['0' '>0']\n",
      "DIF_COMPTEL_LAST_180DAY_G2  ['0' '>0']\n",
      "DIF_CONT_SS_LAST_180DAY  ['0' '>0']\n",
      "DIF_EDUCATION_LAST_180DAY  ['0' '>0']\n",
      "DIF_FAMSTATUS_LAST_180DAY  ['0' '>0']\n",
      "DIF_FAMSTATUS_LAST_90DAY  ['0' '>0']\n",
      "DIF_FMQNTY_LAST_180DAY  ['0' '>0']\n",
      "DIF_INN_BY_CELLTEL_LAST_180DAY  ['0' '>0']\n",
      "DIF_INN_BY_CELLTEL_LAST_30DAY  ['0' '>0']\n",
      "DIF_INN_BY_CONT_SS_LAST_180_  ['0' '>0']\n",
      "DIF_INN_BY_HOMETL_LST_30DAYSG2  ['0' '>0']\n",
      "DIF_MSGREGION_LAST_60_80  ['0' '<180']\n",
      "DIF_MSGREGION_LAST_60DAY  ['0' '>0']\n",
      "DIF_REGTEL_LAST_180DAY  ['0' '>0']\n",
      "DIF_SOCSTATUS_LAST_180DAY_G2  ['0' '>0']\n",
      "DIF_TP_LAST_90DAY_G2  ['0' '>0']\n",
      "DIF_3PESTEL_LAST_180DAY_G2  ['0' '>0']\n",
      "DIF_INN_BY_CELLTEL_LAST_30_  ['0' '>0']\n"
     ]
    }
   ],
   "source": [
    "columns_list = df_clean.columns\n",
    "binary_class_cols = []\n",
    "for col in columns_list:\n",
    "    tmp = df_clean[col].unique()\n",
    "    if len(tmp) == 2:\n",
    "        binary_class_cols.append(col)\n",
    "        print(\"{}  {}\".format(col,tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理思路：\n",
    "\n",
    "在所有变量中，除 `WEEK_DAY`和`DDATE`，其他全部为分类变量。从上可得所有变量中，类别范围仅为2种的变量。其中，`TARGET` 和 `LOYALTY_STATUS` ，`CONTACT_IN_BL` 的取值为 0 或 1，其他变量取值范围为：0 或 >0， 0 或 <180 。\n",
    "> 1. 取值为 '0'/'1' 的分类变量保持不变，类型变为数值型\n",
    "> 2. 取值为 '0'/'>0' 和 '0'/'<180' 的分类变量将不为0的取值改为1\n",
    "> 3. 取值范围大于2类的分类变量，生成one-hot vectors（id化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. change the data type\n",
    "df_clean['TARGET'] = df_clean['TARGET'].astype(int)\n",
    "df_clean['LOYALTY_STATUS'] = df_clean['LOYALTY_STATUS'].astype(int)\n",
    "df_clean['CONTACT_IN_BL'] = df_clean['CONTACT_IN_BL'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. change the values\n",
    "for col in binary_class_cols[3:]:\n",
    "    df_clean[col] = df_clean[col].apply(lambda x: 0 if x=='0' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "247\n"
     ]
    }
   ],
   "source": [
    "# 3. one hot vectors\n",
    "other_class_cols = [c for c in columns_list if c not in binary_class_cols]\n",
    "other_class_cols = other_class_cols[1:-4]\n",
    "\n",
    "for i, col in enumerate(other_class_cols):\n",
    "    if i == 0:\n",
    "        id_cols = pd.get_dummies(df_clean[col], prefix = col).astype(int)\n",
    "    else:\n",
    "        id_cols = id_cols.join(pd.get_dummies(df_clean[col], prefix = col).astype(int))\n",
    "        \n",
    "# check whether the columns number is correct\n",
    "print(len(id_cols.columns) == sum([len(df_clean[col].unique()) for col in other_class_cols]))\n",
    "\n",
    "# join the table\n",
    "df_clean = df_clean.join(id_cols).drop(other_class_cols, axis=1)\n",
    "print(len(df_clean.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID2', 'cos_month', 'cos_week_day', 'sin_month', 'sin_week_day']\n"
     ]
    }
   ],
   "source": [
    "# SUMMARY:\n",
    "# the columns which are not modified in STEP 2-31\n",
    "print([col for col in columns_list if col not in other_class_cols and col not in binary_class_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"assessment\"></a>\n",
    "# 其他： Assessment Data 处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上两个部分就是对training data的简单清洗，现在按照之前处理training data的顺序处理assessment data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 0 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "validation_wb = open_workbook('assessment_sample.xlsb')\n",
    "validation_sheet = validation_wb.get_sheet('TEST')\n",
    "validation_data = []\n",
    "for i, row in enumerate(validation_sheet.rows()):\n",
    "    row_cells = []\n",
    "    for j, cell in enumerate(row):\n",
    "        #'DDATE' is the 3rd column now\n",
    "        row_cells.append(convert_date(cell.v) if j == 3 and i > 0 else cell.v)\n",
    "    validation_data.append(row_cells)\n",
    "validation_wb.close()\n",
    "# generate the dataframe based on the data\n",
    "validation_df = pd.DataFrame(validation_data, columns = validation_data[0])\n",
    "validation_df = validation_df.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# co### STEP 0py the dataframe\n",
    "validation_df_clean = validation_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1-1 缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col#9 \"COMPFIELD\" : 418\n",
      "col#12 \"APPWPERIOD_R2\" : 655\n",
      "col#13 \"APPCHILDQNTY\" : 7200\n",
      "col#63 \"FIRST_DEALNO_LAG\" : 153387\n"
     ]
    }
   ],
   "source": [
    "# count the missing values number in each coloumn\n",
    "# the columns with missing values are the same as those in the training data\n",
    "for i, col_name in enumerate(validation_data[0]):\n",
    "    count = validation_df_clean[col_name].isnull().sum().sum()\n",
    "    if count > 0:\n",
    "        print(\"col#{} \\\"{}\\\" : {}\".format(i+1, col_name, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the missing value into 'isMissing'\n",
    "validation_df_clean['COMPFIELD'] = validation_df_clean['COMPFIELD'].apply(lambda x: 'isMissing' if x is np.NaN or x is None else x)\n",
    "validation_df_clean['APPWPERIOD_R2'] = validation_df_clean['APPWPERIOD_R2'].apply(lambda x: 'isMissing' if x is np.NaN or x is None else x)\n",
    "validation_df_clean['APPCHILDQNTY'] = validation_df_clean['APPCHILDQNTY'].apply(lambda x: 'isMissing' if x is np.NaN or x is None else x)\n",
    "validation_df_clean['FIRST_DEALNO_LAG'] = validation_df_clean['FIRST_DEALNO_LAG'].apply(lambda x: 'isMissing' if x is np.NaN or x is None else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1-2 异常值、重复值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1-3', 90285),\n",
       " ('0', 83292),\n",
       " ('isMissing', 7200),\n",
       " ('>3', 744),\n",
       " ('8', 7),\n",
       " ('10', 7),\n",
       " ('11', 2),\n",
       " ('9', 2),\n",
       " ('13', 1),\n",
       " ('12', 1)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the outliers\n",
    "# the columns with outliers are the same as those in the training data\n",
    "Counter(list(validation_df_clean['APPCHILDQNTY'])).most_common()\n",
    "#[('### STEP 01-3', 149698), ('0', 134901), ('isMissing', 12127), ('>3', 1169)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1-3', 90285), ('0', 83292), ('isMissing', 7200), ('>3', 764)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df_clean['APPCHILDQNTY'] = validation_df_clean['APPCHILDQNTY'].apply(lambda x: '>3' if x in ['8','9','10','11','12','13'] else x)\n",
    "Counter(list(validation_df_clean['APPCHILDQNTY'])).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# check whether there exsits duplicated rows\n",
    "count = 0\n",
    "for i, result in enumerate(validation_df_clean.duplicated()):\n",
    "    if result == True:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 2-1 处理日期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID2</th>\n",
       "      <th>LOYALTY_STATUS</th>\n",
       "      <th>WEEK_DAY</th>\n",
       "      <th>DDATE</th>\n",
       "      <th>SOCIAL_STATUS</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>AGE_RANGE</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>COMPFIELD</th>\n",
       "      <th>APPFAMILYSTATUS</th>\n",
       "      <th>...</th>\n",
       "      <th>DIF_CELLTEL_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_CELLTEL_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_CELLTEL_LAST_30_</th>\n",
       "      <th>DIF_CNT_SPEC_ALLPERIOD</th>\n",
       "      <th>DIF_INN_CNT_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_3PERTEL_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_HOMETEL_ALLPERIOD</th>\n",
       "      <th>FIRST_DEALNO_LAG</th>\n",
       "      <th>DIF_INN_BY_COMPTEL_LAST_180_</th>\n",
       "      <th>DIF_INN_BY_COMPTEL_LAST_30_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>297898</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>pensioner</td>\n",
       "      <td>13-17</td>\n",
       "      <td>50-54</td>\n",
       "      <td>higher</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297899</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>wage worker</td>\n",
       "      <td>&gt;18</td>\n",
       "      <td>50-54</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>02</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297900</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>pensioner</td>\n",
       "      <td>12</td>\n",
       "      <td>&gt;54</td>\n",
       "      <td>higher</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>297901</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>wage worker</td>\n",
       "      <td>13-17</td>\n",
       "      <td>50-54</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>297902</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>wage worker</td>\n",
       "      <td>13-17</td>\n",
       "      <td>35-39</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>08</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID2 LOYALTY_STATUS WEEK_DAY  DDATE SOCIAL_STATUS   HOUR AGE_RANGE  \\\n",
       "1  297898              1        1     12     pensioner  13-17     50-54   \n",
       "2  297899              1        2     12   wage worker    >18     50-54   \n",
       "3  297900              0        6     12     pensioner     12       >54   \n",
       "4  297901              0        7     12   wage worker  13-17     50-54   \n",
       "5  297902              1        7     12   wage worker  13-17     35-39   \n",
       "\n",
       "         EDUCATION COMPFIELD APPFAMILYSTATUS             ...              \\\n",
       "1           higher        12               1             ...               \n",
       "2  upper-secondary        02               2             ...               \n",
       "3           higher        12               1             ...               \n",
       "4  upper-secondary        02               1             ...               \n",
       "5  upper-secondary        08               1             ...               \n",
       "\n",
       "  DIF_CELLTEL_ALLPERIOD DIF_INN_BY_CELLTEL_ALLPERIOD  \\\n",
       "1                     0                            0   \n",
       "2                     1                            0   \n",
       "3                     0                            1   \n",
       "4                     0                            0   \n",
       "5                     0                            0   \n",
       "\n",
       "  DIF_INN_BY_CELLTEL_LAST_30_ DIF_CNT_SPEC_ALLPERIOD DIF_INN_CNT_ALLPERIOD  \\\n",
       "1                           0                      2                     0   \n",
       "2                           0                      4                     0   \n",
       "3                           0                      0                     1   \n",
       "4                           0                      0                     0   \n",
       "5                           0                      5                     0   \n",
       "\n",
       "  DIF_INN_BY_3PERTEL_ALLPERIOD DIF_INN_BY_HOMETEL_ALLPERIOD FIRST_DEALNO_LAG  \\\n",
       "1                            1                            2        isMissing   \n",
       "2                            0                            1        isMissing   \n",
       "3                            1                            1        isMissing   \n",
       "4                            0                            0        isMissing   \n",
       "5                            0                            0        isMissing   \n",
       "\n",
       "  DIF_INN_BY_COMPTEL_LAST_180_ DIF_INN_BY_COMPTEL_LAST_30_  \n",
       "1                            0                           0  \n",
       "2                            0                           0  \n",
       "3                            0                           0  \n",
       "4                            1                           0  \n",
       "5                            0                           0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df_clean['DDATE'] = validation_df_clean['DDATE'].apply(lambda x: x.month)\n",
    "validation_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 55811,\n",
       "         2: 51256,\n",
       "         8: 12062,\n",
       "         9: 12268,\n",
       "         10: 12531,\n",
       "         11: 14041,\n",
       "         12: 23572})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(list(validation_df_clean['DDATE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 2-2 数值标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID2</th>\n",
       "      <th>LOYALTY_STATUS</th>\n",
       "      <th>SOCIAL_STATUS</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>AGE_RANGE</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>COMPFIELD</th>\n",
       "      <th>APPFAMILYSTATUS</th>\n",
       "      <th>COMPSTAFFQNTY</th>\n",
       "      <th>APPWPERIOD_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>DIF_INN_CNT_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_3PERTEL_ALLPERIOD</th>\n",
       "      <th>DIF_INN_BY_HOMETEL_ALLPERIOD</th>\n",
       "      <th>FIRST_DEALNO_LAG</th>\n",
       "      <th>DIF_INN_BY_COMPTEL_LAST_180_</th>\n",
       "      <th>DIF_INN_BY_COMPTEL_LAST_30_</th>\n",
       "      <th>cos_month</th>\n",
       "      <th>cos_week_day</th>\n",
       "      <th>sin_month</th>\n",
       "      <th>sin_week_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>297898</td>\n",
       "      <td>1</td>\n",
       "      <td>pensioner</td>\n",
       "      <td>13-17</td>\n",
       "      <td>50-54</td>\n",
       "      <td>higher</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&gt;5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>7.818315e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297899</td>\n",
       "      <td>1</td>\n",
       "      <td>wage worker</td>\n",
       "      <td>&gt;18</td>\n",
       "      <td>50-54</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>02</td>\n",
       "      <td>2</td>\n",
       "      <td>&gt;50</td>\n",
       "      <td>&gt;5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>9.749279e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297900</td>\n",
       "      <td>0</td>\n",
       "      <td>pensioner</td>\n",
       "      <td>12</td>\n",
       "      <td>&gt;54</td>\n",
       "      <td>higher</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&gt;5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>-7.818315e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>297901</td>\n",
       "      <td>0</td>\n",
       "      <td>wage worker</td>\n",
       "      <td>13-17</td>\n",
       "      <td>50-54</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>02</td>\n",
       "      <td>1</td>\n",
       "      <td>&gt;50</td>\n",
       "      <td>&gt;5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>297902</td>\n",
       "      <td>1</td>\n",
       "      <td>wage worker</td>\n",
       "      <td>13-17</td>\n",
       "      <td>35-39</td>\n",
       "      <td>upper-secondary</td>\n",
       "      <td>08</td>\n",
       "      <td>1</td>\n",
       "      <td>&gt;50</td>\n",
       "      <td>&gt;5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>isMissing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID2 LOYALTY_STATUS SOCIAL_STATUS   HOUR AGE_RANGE        EDUCATION  \\\n",
       "1  297898              1     pensioner  13-17     50-54           higher   \n",
       "2  297899              1   wage worker    >18     50-54  upper-secondary   \n",
       "3  297900              0     pensioner     12       >54           higher   \n",
       "4  297901              0   wage worker  13-17     50-54  upper-secondary   \n",
       "5  297902              1   wage worker  13-17     35-39  upper-secondary   \n",
       "\n",
       "  COMPFIELD APPFAMILYSTATUS COMPSTAFFQNTY APPWPERIOD_R2      ...       \\\n",
       "1        12               1             1            >5      ...        \n",
       "2        02               2           >50            >5      ...        \n",
       "3        12               1             1            >5      ...        \n",
       "4        02               1           >50            >5      ...        \n",
       "5        08               1           >50            >5      ...        \n",
       "\n",
       "  DIF_INN_CNT_ALLPERIOD DIF_INN_BY_3PERTEL_ALLPERIOD  \\\n",
       "1                     0                            1   \n",
       "2                     0                            0   \n",
       "3                     1                            1   \n",
       "4                     0                            0   \n",
       "5                     0                            0   \n",
       "\n",
       "  DIF_INN_BY_HOMETEL_ALLPERIOD FIRST_DEALNO_LAG DIF_INN_BY_COMPTEL_LAST_180_  \\\n",
       "1                            2        isMissing                            0   \n",
       "2                            1        isMissing                            0   \n",
       "3                            1        isMissing                            0   \n",
       "4                            0        isMissing                            1   \n",
       "5                            0        isMissing                            0   \n",
       "\n",
       "  DIF_INN_BY_COMPTEL_LAST_30_ cos_month cos_week_day     sin_month  \\\n",
       "1                           0       1.0     0.623490 -2.449294e-16   \n",
       "2                           0       1.0    -0.222521 -2.449294e-16   \n",
       "3                           0       1.0     0.623490 -2.449294e-16   \n",
       "4                           0       1.0     1.000000 -2.449294e-16   \n",
       "5                           0       1.0     1.000000 -2.449294e-16   \n",
       "\n",
       "   sin_week_day  \n",
       "1  7.818315e-01  \n",
       "2  9.749279e-01  \n",
       "3 -7.818315e-01  \n",
       "4 -2.449294e-16  \n",
       "5 -2.449294e-16  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df_clean['WEEK_DAY'] = validation_df_clean['WEEK_DAY'].astype(int)\n",
    "\n",
    "validation_sin_wd = validation_df_clean['WEEK_DAY'].apply(lambda x: math.sin(2*np.pi*x/float(7)))\n",
    "validation_cos_wd = validation_df_clean['WEEK_DAY'].apply(lambda x: math.cos(2*np.pi*x/float(7)))\n",
    "validation_sin_m = validation_df_clean['DDATE'].apply(lambda x: math.sin(2*np.pi*x/float(12)))\n",
    "validation_cos_m = validation_df_clean['DDATE'].apply(lambda x: math.cos(2*np.pi*x/float(12)))\n",
    "\n",
    "validation_df_clean = validation_df_clean.assign(sin_week_day = validation_sin_wd, \n",
    "                                                 cos_week_day = validation_cos_wd, \n",
    "                                                 sin_month = validation_sin_m, \n",
    "                                                 cos_month = validation_cos_m).drop(['WEEK_DAY', 'DDATE'], axis=1)\n",
    "validation_df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 2-3 分类变量处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOYALTY_STATUS  [1.0 0.0]\n",
      "CONTACT_IN_BL  ['0' '1']\n",
      "DIF_CELLTEL_LAST_180DAY  ['0' '>0']\n",
      "DIF_CHILDQNTY_LAST_180DAY  ['0' '>0']\n",
      "DIF_COMPTEL_LAST_180DAY_G2  ['0' '>0']\n",
      "DIF_CONT_SS_LAST_180DAY  ['0' '>0']\n",
      "DIF_EDUCATION_LAST_180DAY  ['0' '>0']\n",
      "DIF_FAMSTATUS_LAST_180DAY  ['0' '>0']\n",
      "DIF_FAMSTATUS_LAST_90DAY  ['0' '>0']\n",
      "DIF_FMQNTY_LAST_180DAY  ['0' '>0']\n",
      "DIF_INN_BY_CELLTEL_LAST_180DAY  ['0' '>0']\n",
      "DIF_INN_BY_CELLTEL_LAST_30DAY  ['0' '>0']\n",
      "DIF_INN_BY_CONT_SS_LAST_180_  ['0' '>0']\n",
      "DIF_INN_BY_HOMETL_LST_30DAYSG2  ['0' '>0']\n",
      "DIF_MSGREGION_LAST_60_80  ['0' '<180']\n",
      "DIF_MSGREGION_LAST_60DAY  ['0' '>0']\n",
      "DIF_REGTEL_LAST_180DAY  ['0' '>0']\n",
      "DIF_SOCSTATUS_LAST_180DAY_G2  ['0' '>0']\n",
      "DIF_TP_LAST_90DAY_G2  ['0' '>0']\n",
      "DIF_3PESTEL_LAST_180DAY_G2  ['0' '>0']\n",
      "DIF_INN_BY_CELLTEL_LAST_30_  ['0' '>0']\n"
     ]
    }
   ],
   "source": [
    "validation_columns_list = validation_df_clean.columns\n",
    "validation_binary_class_cols = []\n",
    "for col in validation_columns_list:\n",
    "    tmp = validation_df_clean[col].unique()\n",
    "    if len(tmp) == 2:\n",
    "        print(\"{}  {}\".format(col,tmp))\n",
    "        validation_binary_class_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. change the data type\n",
    "validation_df_clean['LOYALTY_STATUS'] = validation_df_clean['LOYALTY_STATUS'].astype(int)\n",
    "validation_df_clean['CONTACT_IN_BL'] = validation_df_clean['CONTACT_IN_BL'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. change the values\n",
    "for col in validation_binary_class_cols[2:]:\n",
    "    validation_df_clean[col] = validation_df_clean[col].apply(lambda x: 0 if x=='0' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. one hot vectors\n",
    "validation_other_class_cols = [c for c in validation_columns_list if c not in validation_binary_class_cols]\n",
    "validation_other_class_cols = validation_other_class_cols[1:-4]\n",
    "\n",
    "for i, col in enumerate(validation_other_class_cols):\n",
    "    if i == 0:\n",
    "        validation_id_cols = pd.get_dummies(validation_df_clean[col], prefix = col).astype(int)\n",
    "    else:\n",
    "        validation_id_cols = id_cols.join(pd.get_dummies(validation_df_clean[col], prefix = col).astype(int))\n",
    "\n",
    "# join the table\n",
    "validation_df_clean = validation_df_clean.join(validation_id_cols).drop(validation_other_class_cols, axis=1)\n",
    "print(len(validation_df_clean.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 检查训练数据和评估数据是否有相同的变量\n",
    "发现多余的变量均是异常值（统计数目为1条数据），于是进行简易删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOUR_1\n",
      "APPWPERIOD_R2_.5\n",
      "DIF_INN_BY_CELLTEL_ALLPERIOD_7.0\n",
      "***\n",
      "DIF_INN_BY_CELLTEL_ALLPERIOD_4.0\n"
     ]
    }
   ],
   "source": [
    "for a in id_cols.columns:\n",
    "    if a not in validation_id_cols.columns:\n",
    "        print(a)\n",
    "print('***')\n",
    "for a in validation_id_cols.columns:\n",
    "    if a not in id_cols.columns:\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with some missing outliers & not neccesary columns\n",
    "df_clean = df_clean.drop(['HOUR_1', 'APPWPERIOD_R2_.5', 'DIF_INN_BY_CELLTEL_ALLPERIOD_7.0'], axis = 1)\n",
    "validation_df_clean = validation_df_clean.drop(['DIF_INN_BY_CELLTEL_ALLPERIOD_4.0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对结果进行备份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('cleaned_development_sample.csv')\n",
    "validation_df_clean.to_csv('cleaned_assessment_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"resample\"></a>\n",
    "# STEP 3. 数据重新采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv('cleaned_development_sample.csv').drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(0, 292497), (1, 5398)])\n"
     ]
    }
   ],
   "source": [
    "print(Counter(df_clean['TARGET']).items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理思路：\n",
    "由上可知，在训练样本中，标签为 `1（bad）` 的数据仅有5000多条，不到所有数据的 2%。样本分布非常不均衡，如果直接使用该样本训练模型，最终可能导致模型将所有数据都分为 `0`，这样虽然可以达到 98% 的正确率，但是并不是我们想要的结果。对数据分布不均衡可以有如下处理方式：\n",
    "> 1. 向下（欠）采样：最简单的方式是对数据较少的类进行随机放回抽样，属于非启发式方法。启发式算法有Tomek links、NearMiss\n",
    "> 2. 向上（过）采样：最简单的方式是对数据较多的类进行随机不放回抽样，也属于非启发式方法。启发式算法有SMOTE\n",
    "> 3. 综合采样：启发式算法有SMOTE+Tomek links、SMOTE+ENN\n",
    "\n",
    "##### python的实现：\n",
    "> * 对于非启发式的方法，python中使用 `sklearn.utils.resample` 可以实现\n",
    "> * 启发式的算法，使用 `imbalanced-learn` 可以实现（http://contrib.scikit-learn.org/imbalanced-learn/stable/install.html）\n",
    "\n",
    "### 最终采取方式：\n",
    "> * 我先使用SOMTE+ENN算法（根据官方介绍文档，该算法相比SMOTE+Tomek Links更能消除噪音），在重新采样之后，新的Development data变成了`X_resampled`和`y_resampled`，不过label中 1 和 0 的比例大致变成 3：1（ \\[(0, 78584), (1, 239038)\\] ），这个非常奇怪。之后试图使用down-sampling的方法，但是运行速度非常慢，效果也不理想。\n",
    "> * 最终选择非启发式的方法，将数据比例调整成为1：3。但是这个方法有个很大的缺点： <FONT COLOR = 'RED'>因为对少数类样本进行放回抽样，就算做了交叉检验也会出现最终得到估算的正确率比实际高的情况。</FONT>\n",
    "\n",
    "#### （问题）\n",
    "> * 1. 应该采取什么方式（启发式/非启发式）平衡数据？\n",
    "> * 2. 采样应该在数据变量预处理（指缺失值、异常值、变量标准化）之前还是之后？\n",
    "> * 3. 数据不同类别的比例应该为多少比较合适？具体数值应该为多少比较合适？（例如在这个问题里，标签为 `1` 的数据只有5000多条，如果把 `0` 的数据减少到 5000~50000 条，会损失很多训练数据；但如果把 `1` 重复抽样到 50000 条，会出现很多重复数据）\n",
    "> * 4. 在反欺诈问题中，是否允许大量标签为 `1` 的重复样本多次出现的情况？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean.drop('TARGET', axis = 1)\n",
    "y = df_clean['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 78584), (1, 239038)]\n"
     ]
    }
   ],
   "source": [
    "# SMOTE + ENN\n",
    "# The result seems not very good\n",
    "smote_enn = SMOTEENN(random_state = 123)\n",
    "X_smoteenn, y_smoteenn = smote_enn.fit_sample(X, y)\n",
    "print(sorted(Counter(y_smoteenn).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 150000), (1, 50000)]\n"
     ]
    }
   ],
   "source": [
    "# Random Select\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df_clean[df_clean.TARGET==0]\n",
    "df_minority = df_clean[df_clean.TARGET==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=50000,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=150000,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_up_down_sampled = pd.concat([df_majority_downsampled, df_minority_upsampled])\n",
    "\n",
    "# Get the X, y values\n",
    "X_resampled = df_up_down_sampled.drop('TARGET', axis = 1)\n",
    "y_resampled = df_up_down_sampled['TARGET']\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"features\"></a>\n",
    "# STEP 4. 特征选择 & 特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理思路：\n",
    "因为该数据几乎全部变量都为分类变量，我不是很清楚使用PCA来进行特征提取（需要变量经过标准化处理且为正态分布）或者使用线性相关分析等方式进行特征选择是否能得出比较好的结果。所以在这一部分，我选择不对变量进行选择或者提取，在具体建模的时候通过改变正则化的惩罚值来对变量进行筛除。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"models\"></a>\n",
    "# STEP 5. 建模\n",
    "### 处理思路：\n",
    "1. 不能使用 [K-NN](#knn) 模型，因为原数据不平衡，在随机综合采样之后，把标签为 `1` 的数据人为重复了多次，K-NN结果会没有意义\n",
    "2. 以下尝试使用 [逻辑回归](#lr) 、[支持向量机](#svm) 和 [随机森林](#rf)\n",
    "3. 使用交叉检验的方式选出最合理的参数\n",
    "\n",
    "#### （问题）\n",
    "1. 对于反欺诈类型的数据问题应该选择什么样的模型比较好？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"lr\"></a>\n",
    "# STEP 5-1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理思路：\n",
    "> 1. 使用 `GridSearchCV` 调整参数，对regularization's penalty value（即 `C` 值）进行选择和交叉检验（5-fold cross validationa），评分为’average_precision‘\n",
    "> 2. 选出最佳模型的参数，建模\n",
    "\n",
    "### 结果：\n",
    "> * 尝试了不同的数据采样比例和采样方式，发现Logistic Regression还是不能识别出 label = 1 的变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model.logistic import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2505840854780201\n",
      "{'C': 0.01}\n",
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# 调整参数\n",
    "# define the parameter values that should be searched\n",
    "param_grid = {\"C\": [0.01, 0.05, 0.1, 0.5, 1]}\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# instantiate the grid\n",
    "# AP summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold\n",
    "# with the increase in recall from the previous threshold used as the weight\n",
    "grid = GridSearchCV(lr, param_grid, cv = 5, scoring = 'average_precision')\n",
    "\n",
    "# fit the grid with data\n",
    "grid.fit(X_resampled, y_resampled)\n",
    "\n",
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_) \n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测类： [0]\n",
      "准确率： 0.75\n",
      "精确率： 0.0\n",
      "召回率： 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# fit the model with the best params\n",
    "lr = LogisticRegression(C = 0.01)\n",
    "clf_lr= lr.fit(X_resampled, y_resampled)\n",
    "pred_y = clf_lr.predict(X_resampled)\n",
    "\n",
    "# get the detailed information\n",
    "print('预测类：', np.unique(pred_y))\n",
    "print('准确率：', accuracy_score(y_resampled, pred_y))  \n",
    "print('精确率：', precision_score(y_resampled, pred_y))  \n",
    "print('召回率：', recall_score(y_resampled, pred_y))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"svm\"></a>\n",
    "# STEP 5-2. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理思路：\n",
    "> 1. 使用 `GridSearchCV` 调整参数，对 `C` 值和 `kernel`、`class_weight` 进行选择和交叉检验（5-fold cross validationa），评分为’average_precision‘\n",
    "> 2. 选出最佳模型的参数，建模\n",
    "\n",
    "### 结果：\n",
    "> * SVC速度很慢，跑了一个多小时都没能出结果，所以以下仅为代码，并没有实际运行的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter values that should be searched\n",
    "param_grid = {\"C\":[0.1, 0.5, 1], \n",
    "              \"kernel\":['rbf','linear'], \n",
    "              \"class_weight\":['', 'balanced']}\n",
    "svc = SVC()\n",
    "\n",
    "# instantiate the grid\n",
    "grid = GridSearchCV(svc, param_grid, cv = 5, scoring = 'average_precision')\n",
    "\n",
    "# fit the grid with data\n",
    "grid.fit(X_resampled, y_resampled)\n",
    "\n",
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)  \n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with the best params\n",
    "svc = SVC(C = 1, kernel = 'linear')\n",
    "clf_svc = svc.fit(X_resampled, y_resampled)\n",
    "pred_y = clf_svc.predict(X_resampled)\n",
    "\n",
    "# get the detailed information\n",
    "print('预测类：', np.unique(pred_y))\n",
    "print('准确率：', accuracy_score(y_resampled, pred_y))  \n",
    "print('精确率：', precision_score(y_resampled, pred_y))  \n",
    "print('召回率：', recall_score(y_resampled, pred_y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"rf\"></a>\n",
    "# STEP 5-3. Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理思路：\n",
    "> 1. 使用 `GridSearchCV` 调整参数，对 `max_depth` 和 `n_estimators` 进行选择和交叉检验（5-fold cross validationa），评分为’average_precision‘\n",
    "> 2. 选出最佳模型的参数，建模\n",
    "> 3. 经查阅，决策树往往在类别不均衡数据上表现不错，随机森林不太会被数据不平衡影响（有待进一步学习），所以直接使用原始 X 和 y。\n",
    "\n",
    "### 结果：\n",
    "> * 选择出来`max_depth` 最佳值为10， `n_estimators` 最佳值为30。以此建模\n",
    "\n",
    "#### （问题）\n",
    "> * 在CV下选择出来的参数建模的召回率很低，但是反欺诈数据分析应该更在乎召回率？如果仅使用 `n_estimators` = 30 来建模虽然召回率和精确率都很高，但是不对树的深度进行规范，是否会出现过拟合的现象（尽管随机森林不容易出现过拟合）？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06222975906916061\n",
      "{'max_depth': 15, 'n_estimators': 30}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
      "            oob_score=False, random_state=10, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# define the parameter values that should be searched\n",
    "param_grid = {\"max_depth\": [None, 10, 15], \n",
    "              \"n_estimators\":[10, 20, 30]}\n",
    "rf = RandomForestClassifier(random_state=10)\n",
    "\n",
    "# instantiate the grid\n",
    "grid = GridSearchCV(rf, param_grid, cv = 5, scoring = 'average_precision')\n",
    "\n",
    "# fit the grid with data\n",
    "grid.fit(X, y)\n",
    "\n",
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)  \n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测类： [0 1]\n",
      "准确率： 0.9989392235519227\n",
      "精确率： 1.0\n",
      "召回率： 0.9414597999258985\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=30)\n",
    "clf_rf = rf.fit(X, y)\n",
    "pred_y = clf_rf.predict(X)\n",
    "\n",
    "# get the detailed information\n",
    "print('预测类：', np.unique(pred_y))\n",
    "print('准确率：', accuracy_score(y, pred_y))  \n",
    "print('精确率：', precision_score(y, pred_y))  \n",
    "print('召回率：', recall_score(y, pred_y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测类： [0 1]\n",
      "准确率： 0.982970509743366\n",
      "精确率： 1.0\n",
      "召回率： 0.060207484253427195\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=30, max_depth=15)\n",
    "clf_rf = rf.fit(X, y)\n",
    "pred_y = clf_rf.predict(X)\n",
    "\n",
    "# get the detailed information\n",
    "print('预测类：', np.unique(pred_y))\n",
    "print('准确率：', accuracy_score(y, pred_y))  \n",
    "print('精确率：', precision_score(y, pred_y))  \n",
    "print('召回率：', recall_score(y, pred_y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其他：K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思路：\n",
    "为了检验K-NN确实不是有用的模型，我稍微做了一下尝试。最终结果，CV选择的 `n_neighbors` 参数为10, 大概正好符合随机抽取的标签为 `1` 的样本为原来样本10倍这一情况。该模型不可用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.665228293552391\n",
      "{'n_neighbors': 10}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# define the parameter values that should be searched\n",
    "param_grid = {\"n_neighbors\": list(range(10, 20))}\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# instantiate the grid\n",
    "grid = GridSearchCV(knn, param_grid, cv = 3, scoring = 'average_precision')\n",
    "\n",
    "# fit the grid with data\n",
    "grid.fit(X_resampled, y_resampled)\n",
    "\n",
    "# examine the best model\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)  \n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测类： [0 1]\n",
      "准确率： 0.903695\n",
      "精确率： 0.7341376841399693\n",
      "召回率： 0.96382\n"
     ]
    }
   ],
   "source": [
    "# fit the model with the best params\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "clf_knn = knn.fit(X_resampled, y_resampled)\n",
    "pred_y = clf_knn.predict(X_resampled)\n",
    "\n",
    "# get the detailed information\n",
    "print('预测类：', np.unique(pred_y))\n",
    "print('准确率：', accuracy_score(y_resampled, pred_y))  \n",
    "print('精确率：', precision_score(y_resampled, pred_y))  \n",
    "print('召回率：', recall_score(y_resampled, pred_y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"selection\"></a>\n",
    "# STEP 6. 模型选择\n",
    "\n",
    "最终综合了多个模型和结果，选择 Random Forests 进行预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"prediction\"></a>\n",
    "# STEP 7. 预测\n",
    "用之前建的模型对 development data 和 assessment data 进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# development data\n",
    "prob_y = clf_rf.predict_proba(X)\n",
    "prob_y_1 = [x[1] for x in prob_y]\n",
    "df_clean = df_clean.assign(predicted_probability = prob_y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assessment data\n",
    "validation_prob_y = clf_rf.predict_proba(validation_df_clean)\n",
    "validation_prob_y_1 = [x[1] for x in validation_prob_y]\n",
    "validation_df_clean = validation_df_clean.assign(predicted_probability  = validation_prob_y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "df_clean.to_csv('development_sample_with_prob.csv')\n",
    "validation_df_clean.to_csv('assessment_sample_with_prob.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
